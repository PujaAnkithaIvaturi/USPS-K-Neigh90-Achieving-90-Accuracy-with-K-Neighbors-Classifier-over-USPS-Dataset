{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ece71cd",
   "metadata": {},
   "source": [
    "HW 1 CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b982ba",
   "metadata": {},
   "source": [
    "By Group 14\n",
    "1. Vidya, Ramineni (1002082819) \n",
    "2. Puja Ankitha, Ivaturi (1002083111) \n",
    "3. Pavana Aasritha, Pendyala (1002114927) \n",
    "4. Pushpahas, Kuchipudi (1002040696) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b3a4ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "#Installing and Importing the h5py library which provides a interface to the HDF5 file format\n",
    "#!pip install h5py\n",
    "import h5py\n",
    "\n",
    "# Load the USPS dataset from the HDF5 file\n",
    "with h5py.File(\"usps.h5\", \"r\") as file:\n",
    "    # Get the list of keys in the HDF5 file\n",
    "    keys = list(file.keys())  \n",
    "    # Print the keys to see the available datasets\n",
    "    print(keys)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1fb8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the training and testing data and labels from the HDF5 \n",
    "with h5py.File(\"usps.h5\", \"r\") as file:\n",
    "    X_train = file[\"train\"][\"data\"][:]\n",
    "    y_train = file[\"train\"][\"target\"][:]\n",
    "    X_test = file[\"test\"][\"data\"][:]\n",
    "    y_test = file[\"test\"][\"target\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80a525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Pre processing on the training and testing data    \n",
    "#!pip install scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946714a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k = 3\n",
      "For k = 3, The corresponding list scores of which the mean is calculated to get cv score is: [0.96435915 0.94924554 0.95404664 0.94101509 0.96021948]\n",
      "\n",
      "Test Accuracy: 0.927753\n",
      "\n",
      "Confusion Matrix:\n",
      "[[355   0   3   0   0   0   0   0   0   1]\n",
      " [  0 257   0   0   4   0   2   1   0   0]\n",
      " [  8   1 176   3   0   0   2   4   4   0]\n",
      " [  1   0   6 147   0   7   0   2   1   2]\n",
      " [  0   2   4   0 177   1   2   3   0  11]\n",
      " [  7   0   1   5   0 137   0   4   2   4]\n",
      " [  4   0   3   0   2   2 159   0   0   0]\n",
      " [  0   1   1   0   6   0   0 138   0   1]\n",
      " [  6   0   3   3   0   2   0   1 148   3]\n",
      " [  1   0   1   0   2   0   0   5   0 168]]\n",
      "\n",
      "Precision: 0.9256\n",
      "Recall: 0.9193\n",
      "======================================\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "======================================\n",
      "\n",
      "\n",
      "For k = 6\n",
      "For k = 6, The corresponding list scores of which the mean is calculated to get cv score is: [0.96435915 0.94924554 0.95404664 0.94101509 0.96021948]\n",
      "\n",
      "Test Accuracy: 0.922770\n",
      "\n",
      "Confusion Matrix:\n",
      "[[353   0   2   1   0   0   1   1   0   1]\n",
      " [  0 258   0   0   4   0   2   0   0   0]\n",
      " [  7   0 177   3   1   0   2   4   4   0]\n",
      " [  3   0   5 152   0   3   0   1   0   2]\n",
      " [  0   3   5   0 176   1   2   3   0  10]\n",
      " [  5   0   1  10   0 135   0   4   1   4]\n",
      " [  5   0   4   0   2   2 157   0   0   0]\n",
      " [  0   2   1   0   4   0   0 139   0   1]\n",
      " [  8   3   2   7   0   3   1   2 138   2]\n",
      " [  1   0   0   0   1   0   0   7   1 167]]\n",
      "\n",
      "Precision: 0.9211\n",
      "Recall: 0.9138\n",
      "======================================\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "======================================\n",
      "\n",
      "\n",
      "For k = 9\n",
      "For k = 9, The corresponding list scores of which the mean is calculated to get cv score is: [0.96435915 0.94924554 0.95404664 0.94101509 0.96021948]\n",
      "\n",
      "Test Accuracy: 0.923767\n",
      "\n",
      "Confusion Matrix:\n",
      "[[353   0   1   1   1   0   1   1   0   1]\n",
      " [  0 258   0   0   4   0   2   0   0   0]\n",
      " [  8   1 177   1   1   0   2   4   4   0]\n",
      " [  3   0   4 149   0   7   0   2   0   1]\n",
      " [  0   4   4   0 175   0   2   4   0  11]\n",
      " [  8   0   1   7   0 134   0   4   1   5]\n",
      " [  6   0   4   0   2   1 156   0   1   0]\n",
      " [  0   3   1   0   4   0   0 139   0   0]\n",
      " [  7   3   2   3   0   1   0   2 145   3]\n",
      " [  1   0   0   0   1   0   0   6   1 168]]\n",
      "\n",
      "Precision: 0.9237\n",
      "Recall: 0.9150\n",
      "======================================\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "======================================\n",
      "\n",
      "\n",
      "For k = 12\n",
      "For k = 12, The corresponding list scores of which the mean is calculated to get cv score is: [0.96435915 0.94924554 0.95404664 0.94101509 0.96021948]\n",
      "\n",
      "Test Accuracy: 0.914798\n",
      "\n",
      "Confusion Matrix:\n",
      "[[353   0   1   1   1   0   1   1   0   1]\n",
      " [  0 258   0   0   3   0   3   0   0   0]\n",
      " [  8   2 173   3   1   0   2   4   5   0]\n",
      " [  4   0   4 149   0   5   0   2   0   2]\n",
      " [  1   5   4   0 172   0   2   4   0  12]\n",
      " [  9   0   0   6   1 133   0   5   2   4]\n",
      " [  7   0   4   0   2   1 155   0   1   0]\n",
      " [  0   4   1   0   4   0   0 137   0   1]\n",
      " [  8   3   2   6   0   2   1   2 140   2]\n",
      " [  1   0   0   0   1   0   0   7   2 166]]\n",
      "\n",
      "Precision: 0.9150\n",
      "Recall: 0.9048\n",
      "======================================\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "======================================\n",
      "\n",
      "\n",
      "For k = 15\n",
      "For k = 15, The corresponding list scores of which the mean is calculated to get cv score is: [0.96435915 0.94924554 0.95404664 0.94101509 0.96021948]\n",
      "\n",
      "Test Accuracy: 0.914300\n",
      "\n",
      "Confusion Matrix:\n",
      "[[353   0   1   1   1   0   1   1   0   1]\n",
      " [  0 258   0   0   3   0   3   0   0   0]\n",
      " [  8   3 170   4   2   0   1   5   5   0]\n",
      " [  4   0   4 149   0   5   0   2   0   2]\n",
      " [  1   5   4   0 172   0   1   5   0  12]\n",
      " [  9   0   0   7   1 132   0   4   2   5]\n",
      " [  5   0   4   0   2   1 157   0   1   0]\n",
      " [  0   3   0   1   4   0   0 138   0   1]\n",
      " [  7   3   2   7   0   2   2   2 138   3]\n",
      " [  1   0   0   0   1   0   0   6   1 168]]\n",
      "\n",
      "Precision: 0.9138\n",
      "Recall: 0.9045\n",
      "======================================\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "======================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Initialize a list to store cross-validation results\n",
    "cv_scores = []\n",
    "list_scores = []\n",
    "\n",
    "\n",
    "\n",
    "#####  TASK 4: Change different K for KNN   #####\n",
    "\n",
    "#Test different values of k\n",
    "k_values = [3, 6, 9, 12, 15]\n",
    "\n",
    "\n",
    "# Performing K-fold cross-validation for different values of K using K nearest neighbors(KNN) classifier\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    #####   TASK 1: Cross validation and accuracy   #####\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    list_scores.append(scores)\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "#Find the best k value with the highest cross-validation accuracy\n",
    "#print(cv_scores)\n",
    "while len(cv_scores)>0:\n",
    "    #Finding the value of k that corresponds to the highest cross validation score\n",
    "    best_k = k_values[cv_scores.index(max(cv_scores))]\n",
    "    print(f\"For k = {best_k}\")\n",
    "    print(\"For k = {0}, The corresponding list scores of which the mean is calculated to get cv score is: {1}\".format(best_k,list_scores[cv_scores.index(max(cv_scores))]))\n",
    "    knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    #Fitting the KNN classifier on the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    #Predicting the labels for the test data\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    #Calculate accuracy\n",
    "    print()\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "    print(f\"Test Accuracy: {accuracy:.6f}\")\n",
    "    \n",
    "    #####   TASK 2: Confusion Matrix     #####\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    print()\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    #####   TASK 3: Precision and Recall  #####\n",
    "    print()\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    \n",
    "\n",
    "    cv_scores.remove(max(cv_scores))\n",
    "    k_values.remove(best_k)\n",
    "    \n",
    "    \n",
    "    print(\"======================================\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"======================================\")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7b2bf2",
   "metadata": {},
   "source": [
    "HW 1 REPORT\n",
    "\n",
    "By Group 14\n",
    "1. Vidya, Ramineni (1002082819) \n",
    "2. Puja Ankitha, Ivaturi (1002083111) \n",
    "3. Pavana Aasritha, Pendyala (1002114927) \n",
    "4. Pushpahas, Kuchipudi (1002040696) \n",
    "\n",
    "\n",
    "Building a USPS Dataset Classifier using K-Nearest Neighbors\n",
    "\n",
    "The main aim of this report is to provide an overview of the tasks performed to build a classifier for the USPS dataset using the K-Nearest Neighbors algorithm. The goal is to achieve over 90% accuracy on the test set, and the following tasks were executed to accomplish this:\n",
    "Note: Here, we ran a loop over different K’s and each of them execute in such a manner that the best K I.e., the one that gives the best accuracy is resulted first, and the second-best accuracy K follows it and so on... I.e., from the best to the worst. \n",
    "\n",
    "For all the K values taken, we achieved over 90% accuracy on the test set.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Task 1: Cross-Validation\n",
    "\n",
    "In this task, we employed K-fold cross-validation to evaluate the performance of the KNN classifier with different values of K [3, 6, 9, 12, 15]. The purpose of cross-validation is to estimate how well the model will generalize to unseen data.\n",
    "To accomplish this, we imported the necessary libraries, including scikit-learn, for KNN and evaluation metrics. A list was initialized to store cross-validation results, and another list was used to record individual scores for each K. Different values of K (3, 6, 9, 12, and 15) were tested. KNN classifiers with each K-value were trained and evaluated using 5-fold cross-validation. The mean accuracy scores for each K were recorded.\n",
    " \n",
    "And here, accuracy is calculated to check which K gives the best result of all others and proceed with that at first.\n",
    "\n",
    "\n",
    "\n",
    "Task 2: Confusion Matrix\n",
    "\n",
    "In this task, we calculated and displayed the confusion matrix to gain insight into the KNN classifier's performance on the test data. A confusion matrix is a valuable tool for understanding the classifier's ability to correctly classify each class.\n",
    "To accomplish this, we used the trained KNN classifier with the best-performing K. Predictions were made on the test data. A confusion matrix was generated to show the number of true positives, true negatives, false positives, and false negatives for each class.\n",
    "\n",
    "\n",
    "\n",
    "Task 3: Precision and Recall\n",
    "\n",
    "In this task, we computed the precision and recall scores to further assess the classifier's performance. Precision measures the accuracy of positive predictions, while recall assesses the ability to find all positive instances.\n",
    "To accomplish this, Precision and recall scores were calculated using the predicted and true labels for each class. We used the 'macro' average to compute a single precision and recall score that considers all classes.\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "Task 4: Change Different K for KNN\n",
    "\n",
    "This task focused on iterating through different values of K for the KNN classifier and finding the K that achieved the highest cross-validation accuracy.\n",
    "To accomplish this: We repeated the K-fold cross-validation procedure for each K in the list of tested values. The K with the highest cross-validation accuracy was identified as the best- performing K. The KNN classifier with the best K was trained on the entire training dataset. Predictions were made on the test data, and accuracy, confusion matrix, precision, and recall were computed.\n",
    "\n",
    "And thereby, the K values are used throughout the program, one at a time, to calculate confusion matrix, recall and precision of best in descending order of accuracy.\n",
    "\n",
    "\n",
    "In conclusion, this report outlined the tasks performed to build a classifier for the USPS dataset using the K-Nearest Neighbors algorithm. By conducting cross-validation, evaluating confusion matrices, and calculating precision and recall scores, we were able to assess and optimize the classifier's performance. Additionally, we iteratively selected the best K for KNN to achieve high accuracy on the test set. The results and insights gained from these tasks are valuable in understanding the classifier's strengths and weaknesses and can aid in further fine-tuning the model for better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa571e4",
   "metadata": {},
   "source": [
    "END OF HW 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
